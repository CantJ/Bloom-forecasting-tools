# This script outlines the JellySim function that serves as the primary basis of the GoJelly predictive tool for forecasting the occurrence of jellyfish blooms.
# The primary purpose of this function is to unify demographic data and hydrodynamic drifting simulations to forecast temporal and spatial patterns in the density of jellyfish medusae within a predefined spatial region

# Primary Author: James Cant
# Contact: james.cant91@gmail.com
# Date last modified: March 2022
# -----------------------------------------------------------------------------

#----------------------------------------------------
# STEP 1: DEFINE PRIMARY FUNCTION
#----------------------------------------------------

# This simulation function forms the basis of the GoJelly Risk Map
JellySim <- function(params, SINMOD_data, n_month, xmx, xmn, ymx, ymn, # data requirements of the function 
                     # a tool built into the function to make it feasible to use this function as part of validation efforts
                     # to validate the model the density projections associated with each release site are required in order to overlay them with observer data.
                     # Although not part of the predictive functionality of this tool this argument can be used to extract all available density predictions for using in validating the model.
                     site.return = FALSE, # within the app this function will be switched off as default.
                     # the interactive app will have the capacity to use pre-extracted density projections in order to speed up run-time.
                     # the argument here will be used to tell the app whether it is using pre-extracted densities.
                     use.defaults, # this is a conditional argument (requires TRUE/FALSE instruction) 
                     # the function also requires feeding with pre-extracted densities
                     def_dens,
                     # user defined parameters
                     rel_location, rel_months, zmax, demo_stoch = TRUE, env_var = TRUE) {
  # This function requires nine key pieces of information:
  # 1) Demographic parameters used to parameterise the periodic population models use to simulation jellyfish dynamics
  # 2) Temperature records experience by drifting particles
  # 3 & 4) The GPS coordinates where these thermal readings are experienced. Data elements 2:4 will be provided simultaneously as one data file (SINMOD_data)
  # 5) The monthly duration of the simulation.
  # The remaining four parameters define the geographical region of interest (used primarily in plotting the risk maps)
  # -------------------------------------------------
  # How the model uses these pieces of data, and displays all subsequent outputs will depend on four user defined parameters:
  # rel_location: a value or vector defining desired locations of Jellyfish release (i.e. seed population location).
  # rel_months: a vector of values between 1 and 12 defining the months during which Jellyfish ephyra are released from polyps. 
  # Note the simulation displays medusae densities, but the Jellyfish are released as Ephyra, and so the simulation will require one time step before Jellyfish would be expected to appear. 
  # zmax: How many iterations should be used to estimate density variation generated by stochasticity 
  # demo_stoch: should demographic stochasticity be incorporated in the model. Defaults to TRUE.
  # env_var: should environmental variability be incorporated in the outputs. Defaults to TRUE.
  # Overall this function returns a list of raster and shape files corresponding with the pathways and densities of jellyfish expected following the release within the Baltic.
  
  # Load package dependencies
  packages <- c("furrr", "progressor", "future", "parallel", "raster", "sf", "data.table")
  lapply(packages, require, character.only = TRUE)
  
  #first the function will define the number of parallel clusters needed.
  num.cores <- length(rel_location)*zmax # cluster size scale with memory demand requests
  plan(multicore, workers = num.cores)
  
  # if the function is not working with pre-extracted densities then a full simulation is required.
  if(use.defaults == FALSE) {
    ### 1. Subset the data based on the user defined release location
    SINMOD_use <- SINMOD_data[SINMOD_data$Index %in% rel_location,]
    # How many release points have been requested
    n_sites <- length(rel_location)
    # check dataframe dimensions match expectations for the simulation. 
    dim.check <- dim(SINMOD_use$Tempmat[[1]])[2] == n_month
    # And how many particles are being released over the full particle tracks 
    n_part <- dim(SINMOD_use$Tempmat[[1]])[1]
    # estimate how days per month are nessecary for this simulation and snip the data to ensure equal temporal dimensions
    n_day <- floor(n_part/n_month)
    # determine the correct dimensions to match those expected by the simulation time frame
    dim.correct <- (n_part - (n_month * n_day))+1
    
    # Store the selected release location GPS coordinates for plotting alongside forecasted densities
    site_coords <- SINMOD_use[, c("Lat", "Lon")]
    class(site_coords) <- "data.frame"
    
    ### 2. Define additional variables needed for simulation
    # Matrix dimension
    m <- 200 
    # Periods during which Ephyra production is not permitted
    ephyra_omit <- seq(1:n_month)
    ephyra_omit <- ephyra_omit[!(ephyra_omit %in% rel_months)]
    
    # set up progress bar
    pb <- progressor(along = 1:length(rel_location))
    
    ### 3. Work through each requested location running density simulations
    site_sim_outputs <- future_map(1:length(rel_location), site_sim, rel_location = rel_location, SINMOD_use = SINMOD_use, ephyra_omit = ephyra_omit, dim.check = dim.check,
                                   n_month = n_month, n_day = n_day, zmax = zmax, n_part = n_part, m = m, params = params, rel_months = rel_months, dim.correct = dim.correct, 
                                   demo_stoch = demo_stoch, pb = pb, .options = furrr_options(seed = NULL))
    
    # and store output densities and GPS coordinates
    Med_den_mean <- lapply(site_sim_outputs, '[[', 1)
    Med_den_sd <- lapply(site_sim_outputs, '[[', 2)
    GPS_lat <- lapply(site_sim_outputs, '[[', 3)
    GPS_lon <- lapply(site_sim_outputs, '[[', 4)
    # and assign output names
    location.name <- sapply(1:n_sites, function(x){ 
      site = rel_location[x]
      paste0("Index ", site) } )
    names(Med_den_mean) <- location.name 
    names(Med_den_sd) <- location.name 
    names(GPS_lat) <- location.name 
    names(GPS_lon) <- location.name
    
  } else { #if the function is working with pre-extracted densities these can be formatted for analysis here ready for rasterising and plotting
    
    # define the number of selected sites
    n_sites <- length(rel_location)
    # define number of days per month
    n_day <- dim(def_dens[["Dens"]][[1]])[3]
    
    # subset pre-extracted density data based on desired release locations
    def_dens_use <- lapply(def_dens, '[', rel_location)
    
    # un-piece pre-extracted density data file
    Med_den_mean <- def_dens_use[["Dens"]]
    # currently this is working as a proof of concept. This line of code is a little fix as no variance estimates were retained for 2019 simulations. 
    Med_den_sd <- def_dens_use[["Dens"]]
    # Med_den_sd <- def_dens_use[["Dens_sd"]]
    GPS_lat <- def_dens_use[["Lat"]]
    GPS_lon <- def_dens_use[["Lon"]]
    
    # Store the selected release location GPS coordinates for plotting alongside forecasted densities
    site_coords_lat <- unlist(lapply(GPS_lat, '[[', 1))
    site_coords_lon <- unlist(lapply(GPS_lon, '[[', 1))
    site_coords <- data.frame(Lat = site_coords_lat,
                              Lon = site_coords_lon)
    class(site_coords) <- "data.frame"
    
  }
  
  # a little break in the code if the individual site data needs returning (used for validation) or if further processing is required (to produce the plot outputs for the interactive app)
  if(site.return == TRUE){
    # for validation, the output only needs to be the different spatial patterns predicted across the different sites
    return(list(Mean_density = Med_den_mean, SD_density = Med_den_sd, lat = GPS_lat, lon = GPS_lon))
    
  } else {
    
    # So the function has now simulated the proportional density of medusae depending on the time of release within the month (30 day period)
    # The following steps will now be to plot these densities on a map and return the visuals.
    # Across each location each array consists of matrices defining medusae density simulations if recorded on a specific day each month (n days = 30)
    # displaying the densities and the variability in densities requires days from each month to be condensed together (i.e corresponding rows across each matrix within the arrays need condensing together) 
    # Here the temporal densities will also be brought together so that all requested sites will be plotted together across each plot.
    # this way regardless of how many sites are requested, the number of plots produced will equal n_month
    
    # condense together days from corresponding months (across all requested sites!)
    tmp_Med_mean <- lapply(1:n_sites, array_reformat, initial_array = Med_den_mean, n_month = n_month)
    tmp_Med_sd <- lapply(1:n_sites, array_reformat, initial_array = Med_den_sd, n_month = n_month)
    tmp_lat <- lapply(1:n_sites, array_reformat, initial_array = GPS_lat, n_month = n_month)
    tmp_lon <- lapply(1:n_sites, array_reformat, initial_array = GPS_lon, n_month = n_month)
    # reformat from site lists into combined arrays
    Med_mean <- do.call(abind, c(lapply(tmp_Med_mean, '['), along = 1))
    Med_sd <- do.call(abind, c(lapply(tmp_Med_sd, '['), along = 1))
    lat <- do.call(abind, c(lapply(tmp_lat, '['), along = 1))
    lon <- do.call(abind, c(lapply(tmp_lon, '['), along = 1))
    
    # Now ensure that each matrices only contains entries for times for which there is corresponding GPS coordinates and visa versa.
    Med_mean[is.na(lat)] <- NA
    Med_sd[is.na(lat)] <- NA
    lat[is.na(Med_mean)] <- NA
    lon[is.na(Med_mean)] <- NA
    
    # This is where the function changes its output depending on whether environmental variability is requested
    if(env_var == TRUE) {
      
      # Strip out each column (across the whole array) to produce temporal rasters displaying how medusae density changes over time (and how within a month the simulations can vary.
      # loop through each matrix quadruplet (Den_mean, dens_sd, Lat, Long)
      # each time extracting successive columns and generating a density raster before storing it (although lapply does this all simultaneously)
      mean_plots <- lapply(1:n_month, combine_rasters, lon = lon, lat = lat, Med_mat = Med_mean, n_day = n_day, method = "mean", xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx, n_month = n_month)
      conf_plots <- lapply(1:n_month, combine_rasters, lon = lon, lat = lat, Med_mat = Med_sd, n_day = n_day, method = "sd", xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx, n_month = n_month)
      
      # rename stored lists
      entry.name <- sapply(1:n_month, function(x){ paste0("Month ", x) } )
      names(mean_plots) <- entry.name
      names(conf_plots) <- entry.name
      
      # and determine the largest proportional density recorded across this particular simulation
      max_mean_den <- roundUpManual(sapply(1:n_month, max_den_calc, list_use = mean_plots))
      max_conf_den <- roundUpManual(sapply(1:n_month, max_den_calc, list_use = conf_plots))
      
      # but if environmental variability is not required.
    } else {
      # to remove environmental variability the function will just assume the first day of the month is required.
      
      # Subset data to return only the densities corresponding with simulations associated with the 
      # first day of each successive months 
      month_index <- seq(1, n_day*n_sites, by = n_day)
      Med_mean_subset <- Med_mean[month_index,,]
      Med_sd_subset <- Med_sd[month_index,,]
      lat_subset <- lat[month_index,,]
      lon_subset <- lon[month_index,,]
      
      # Strip out each column (across the whole array) to produce temporal rasters displaying how medusae density changes over time (and how within a month the simulations can vary.
      # loop through each matrix quadruplet (Den_mean, dens_sd, Lat, Long)
      # each time extracting successive columns and generating a density raster before storing it (although lapply does this all simultaneously)
      mean_plots <- lapply(1:n_month, combine_rasters, lon = lon_subset, lat = lat_subset, Med_mat = Med_mean_subset, n_day = n_day, method = "mean", xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx, n_month = n_month)
      conf_plots <- lapply(1:n_month, combine_rasters, lon = lon_subset, lat = lat_subset, Med_mat = Med_sd_subset, n_day = n_day, method = "sd", xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx, n_month = n_month)
      
      # rename stored lists
      entry.name <- sapply(1:n_month, function(x){ paste0("Month ", x) } )
      names(mean_plots) <- entry.name
      names(conf_plots) <- entry.name
      
      # and determine the largest proportional density recorded across this particular simulation
      max_mean_den <- roundUpManual(sapply(1:n_month, max_den_calc, list_use = mean_plots))
      max_conf_den <- roundUpManual(sapply(1:n_month, max_den_calc, list_use = conf_plots))
    }
    
    # and return desired outputs
    return(list(mean = mean_plots, conf = conf_plots, mean_max = max_mean_den, conf_max = max_conf_den, rel_coords = site_coords))
  }
}

#----------------------------------------------------
# STEP 2: DEFINE INTERNAL FUNCTIONS
#----------------------------------------------------

# 1. Simulation functions called internally within the JellySim function
drift_sim1 <- function(jj, zmax, m, n_day, n_part, n_month, params, Temp, Sal, Lat_site, Lon_site, ephyra_omit, rel_months, demo_stoch){
  # define a repeating count sequence to allow this function to perform stochastic iterations
  iterate_seq <- rep(1:n_day, zmax)
  rd <- iterate_seq[jj]
  
  # generate initial polyp density and define transition functions
  pop_sim <- PeriodicMat(m = m, n_month = n_month, params = params, Temp = Temp[rd,], Sal = Sal[rd,],
                         demo_stoch = demo_stoch)
  # extract the all important indexing parameter
  index <- pop_sim$Adjust
  
  # generate storage of initial polyp density
  Polyp_dens_store <- numeric(n_month+1) # +1 saves indexing errors later
  # and store initial polyp density
  Polyp_dens_store[index] <- pop_sim$DensityStart
  
  # define initial population structure vector
  initial_pop <- numeric(m+4)
  # and insert starting seed population polyp density
  initial_pop[2] <- Polyp_dens_store[index]
  
  # Now ephyra release is only permitted within a user defined period.
  # Thus each periodic matrix needs to be modified to reflect this in the simulations.
  # To do this ephyra production transitions (element 4,2) in all matrices corresponding with periods outside the user defined window need to be set to zero
  pop_sim$matB[4,2,ephyra_omit] <- 0
  # Now following initial Ephyra release the simulation splits into two elements:
  # one element is only interested in the transitions and survival of existing Ephyra/Medusae.
  # the other is interested in how the dynamics of the polyps affects them for the following month.
  # So following initial ephyra release the remaining matrices need to have all transitions prior to ephyra production removed.
  # This can be achieved by removing matrix elements from column 1:3
  # First the function needs to define some indexing values for subsetting ephrya transitions (primarily to prevent subscript issues)
  ephyra.index1 <- min(rel_months)+1
  if(ephyra.index1 > n_month){ephyra.index1 = n_month}
  ephyra.index2 <- min(rel_months)+3
  if(ephyra.index2 > n_month){ephyra.index2 = n_month}
  ephyra.index3 <- index+1
  if(ephyra.index3 > n_month){ephyra.index3 = n_month}
  ephyra.index4 <- index+3
  if(ephyra.index4 > n_month){ephyra.index4 = n_month}
  ephyra.index5 <- max(rel_months) + 3
  if(ephyra.index5 > n_month){ephyra.index5 = n_month}
  # now apply inhibition.
  if(index < min(rel_months)){pop_sim$matB[,1:3, ephyra.index1:n_month] <- 0}
  if(index %in% rel_months){pop_sim$matB[,1:3, ephyra.index3:n_month] <- 0}
  if(index > max(rel_months)){pop_sim$matB[,1:3, ephyra.index1:n_month] <- 0}
  # equally however following their initial release Ephyra are only believed to persist in the water column for 2-3 months
  # Therefore this needs to be defined in the relevant matrices by artificially setting ephyra survival (element 4,4), and medusae production (elements 5:204,4) to zero in matrices corresponding with
  # periods 2-3 months after initial release.
  if(index < min(rel_months)){pop_sim$matB[4:(m+4),4, ephyra.index2:n_month] <- 0}
  if(index %in% rel_months){pop_sim$matB[4:(m+4),4, ephyra.index4:n_month] <- 0}
  if(index > max(rel_months)){pop_sim$matB[4:(m+4),4, ephyra.index5:n_month] <- 0}
  # Also medusae production is not possible in the first month of ephyra production and so needs inhibiting
  if(index < min(rel_months)){pop_sim$matB[5:(m+4),4, min(rel_months)] <- 0}
  if(index %in% rel_months){pop_sim$matB[5:(m+4),4, index] <- 0}
  if(index > max(rel_months)){pop_sim$matB[5:(m+4),4,  min(rel_months)] <- 0}
  
  # create storage for population projections
  nt_med <- matrix(0, nrow = m, ncol = n_month)
  Nt_med <- matrix(NA, nrow = n_month, ncol = n_month)
  Nt_ephyra <- matrix(NA, nrow = n_month, ncol = n_month)
  lat <- matrix(NA, nrow = n_month, ncol = n_month)
  lon <- matrix(NA, nrow = n_month, ncol = n_month)
  
  # run first simulation
  pop_vec <- pop_sim$matB[,,index]%*%initial_pop
  # store required outputs
  nt_med[, index] <- pop_vec[5:204,] 
  Nt_med[1, index] <- pop_sim$h[1] * sum(nt_med[, 1])
  Nt_ephyra[1, index] <- pop_vec[4,]
  # important to retain polyp density for next monthly run through
  Polyp_dens_store[index+1] <- pop_vec[2,]
  
  # Now loop through simulating and storing medusae densities
  for(t in index:n_month){
    pop_vec <- pop_sim$matB[,,t]%*%pop_vec
    nt_med[, t] <- pop_vec[5:204,]
    Nt_med[1, t] <- pop_sim$h[t] * sum(nt_med[, t])
    Nt_ephyra[1, t] <- pop_vec[4,]
  }
  
  # convert medusae density into a relative measure - (the proportion of individuals as a function of the number originally produced)
  e.initial <- head(Nt_ephyra[1,][Nt_ephyra[1,]!=0 & !is.na(Nt_ephyra[1,])], 1) # calculate the number of ephyra initially released
  if(length(e.initial) == 1){ Nt_med[1,] <- Nt_med[1,]/e.initial } # divide medusae densities by this initial release value.
  
  # Finally store the GPS coordinates associated with these simulations
  lat[1,] <- data.table::shift(Lat_site[rd,], n = index-1, fill = NA)
  lon[1,] <- data.table::shift(Lon_site[rd,], n = index-1, fill = NA)
  
  # So far this has simulated the trajectory of a single release. The function now needs to simulate the continued release of ephyra from this initial release point onwards.   
  # For this the function needs to loop back through but each time using the polyp density determined on the previous run.
  # Importantly however the model needs to skip every 30 particle tracks to ensure it is working to monthly time steps.
  dens_sim <- future_map(2:n_month, drift_sim2, rd = rd, n_day = n_day, n_part = n_part, m = m, n_month = n_month, 
                         ephyra_omit = ephyra_omit, params = params, Temp = Temp, Sal = Sal, Polyp_dens_store = Polyp_dens_store, 
                         Lat_site = Lat_site, Lon_site = Lon_site, rel_months = rel_months, demo_stoch = demo_stoch, .options = furrr_options(seed = NULL))
  
  # Now attach these subsequent run-through into the same matrix as the initial run through.
  for(ii in 2:n_month){
    Nt_med[ii,] <- dens_sim[[(ii-1)]]$Nt_med
    lat[ii,] <- dens_sim[[(ii-1)]]$lat
    lon[ii,] <- dens_sim[[(ii-1)]]$lon
  }
  # and return outputs
  return(list(Nt_med = Nt_med, lat = lat, lon = lon))
}

# Drift sim2 is an identical function to drift sim1 except that it subjects polyp and medusae populations to differing abiotic conditions to reflect the divergent difting of medusae populations 
# away from their source polyp population (it is called internally by drift_sim1).
drift_sim2 <- function(ii, rd, n_day, n_part, m, n_month, ephyra_omit, params, Temp, Sal, Polyp_dens_store, Lat_site, Lon_site, rel_months, demo_stoch){
  # calculate iteration identity - this line of code allows this function to the analysis as a string sequence rather than handle as a for loop.
  seq_index <- rd + ((ii-1)*n_day)
  # first a little formatting check to ensure there is enough data left to complete the loop
  # if there is no temperature data the function won't perform properly.
  if(seq_index > n_part){
    Nt_med[ii,] <- NA
    Nt_ephyra[ii,] <- NA
    lat[ii,] <- NA
    lon[ii,] <- NA
  } else {
    # redefine define transition functions - using subsequent polyp density estimates 
    pop_sim <- PeriodicMat(m = m, n_month = n_month, params = params, Temp = Temp[seq_index,], Sal = Sal[seq_index,], demo_stoch = demo_stoch)
    # extract initial population indexing parameter
    index <- pop_sim$Adjust
    # redefine initial population structure vector
    initial_pop <- numeric(m+4)
    # and insert starting seed population polyp density
    initial_pop[2] <- Polyp_dens_store[index]
    
    # Constrain ephyra release
    pop_sim$matB[4,2,ephyra_omit] <- 0
    # Inhibit unnecessary transitions following initial ephyra release
    ephyra.index1 <- min(rel_months)+1
    if(ephyra.index1 > n_month){ephyra.index1 = n_month}
    ephyra.index2 <- min(rel_months)+3
    if(ephyra.index2 > n_month){ephyra.index2 = n_month}
    ephyra.index3 <- index+1
    if(ephyra.index3 > n_month){ephyra.index3 = n_month}
    ephyra.index4 <- index+3
    if(ephyra.index4 > n_month){ephyra.index4 = n_month}
    ephyra.index5 <- max(rel_months) + 3
    if(ephyra.index5 > n_month){ephyra.index5 <- n_month}
    if(index < min(rel_months)){pop_sim$matB[,1:3, ephyra.index1:n_month] <- 0}
    if(index %in% rel_months){pop_sim$matB[,1:3, ephyra.index3:n_month] <- 0}
    if(index > max(rel_months)){pop_sim$matB[,1:3, ephyra.index1:n_month] <- 0}
    if(index < min(rel_months)){pop_sim$matB[4:(m+4),4, ephyra.index2:n_month] <- 0}
    if(index %in% rel_months){pop_sim$matB[4:(m+4),4, ephyra.index4:n_month] <- 0}
    if(index > max(rel_months)){pop_sim$matB[4:(m+4),4, ephyra.index5:n_month] <- 0}
    if(index < min(rel_months)){pop_sim$matB[5:(m+4),4, min(rel_months)] <- 0}
    if(index %in% rel_months){pop_sim$matB[5:(m+4),4, index] <- 0}
    if(index > max(rel_months)){pop_sim$matB[5:(m+4),4,  min(rel_months)] <- 0}
    
    # create storage for population projections
    nt_med <- matrix(0, nrow = m, ncol = n_month)
    Nt_med <- rep(NA, n_month)
    Nt_ephyra <- rep(NA, n_month)
    
    # run first simulation
    pop_vec <- pop_sim$matB[,,index]%*%initial_pop
    # store required outputs
    nt_med[, index] <- pop_vec[5:204,] 
    Nt_med[index] <- pop_sim$h[1] * sum(nt_med[, ii])
    Nt_ephyra[index] <- pop_vec[4,]
    # important to retain polyp density for next monthly run through
    Polyp_dens_store[index+1] <- pop_vec[2,]
    
    # Now loop through simulating and storing medusae densities
    for(t in index:n_month){
      pop_vec <- pop_sim$matB[,,t]%*%pop_vec
      nt_med[, t] <- pop_vec[5:204,]
      Nt_med[t] <- pop_sim$h[t] * sum(nt_med[, t])
      Nt_ephyra[t] <- pop_vec[4,]
    }
    
    # convert medusae density into a relative measure - (the proportion of individuals as a function of the number originally produced)
    e.initial <- head(Nt_ephyra[Nt_ephyra != 0 & !is.na(Nt_ephyra)], 1) # calculate the number of ephyra initially released
    if(length(e.initial) == 1){ Nt_med <- Nt_med/e.initial } # divide medusae densities by this initial release value.
    
    # Finally, store the GPS coordinates associated with these simulations
    lat <- data.table::shift(Lat_site[seq_index,], n = index-1, fill = NA)
    lon <- data.table::shift(Lon_site[seq_index,], n = index-1, fill = NA)
  }
  
  # and return desired outputs
  return(list(Nt_med = Nt_med, lat = lat, lon = lon))
}

# 2. Define function for reformatting arrays to combine observations across corresponding days. 
array_reformat <- function(rp, initial_array, n_month){
  tmp_array <- asplit(initial_array[[rp]][,,], MARGIN = 1) # split apart and condense together corresponding matrix rows from across the array
  new_array <- sapply(1:n_month, function(x){ t(tmp_array[[x]])}, simplify = 'array') # transpose aggregated rows
  return( new_array )
}

# 3. Calculate maximum density.
max_den_calc <- function(ii, list_use){
  x <- max(raster::values(list_use[[ii]]), na.rm = TRUE)
  return(x)
}

# 4. Define function for applying simulations across multiple sites. 
site_sim <- function(rp, rel_location, SINMOD_use, ephyra_omit, dim.check, n_month, n_day, zmax, n_part, m, params, rel_months, dim.correct, demo_stoch, pb){  
  # Define selected site
  site <- rel_location[rp]
  
  # Extract Temperature and GPS details
  Temp <- SINMOD_use[SINMOD_use$Index == site,]$Tempmat[[1]]
  Sal <- SINMOD_use[SINMOD_use$Index == site,]$Salmat[[1]]
  Lat_site <- SINMOD_use[SINMOD_use$Index == site,]$Latmat[[1]]
  Lon_site <- SINMOD_use[SINMOD_use$Index == site,]$Lonmat[[1]]
  
  # A little fix to ensure dataframe dimensions match simulation time frame dimensions
  if(dim.check == FALSE) {
    Temp <- Temp[dim.correct:n_part,1:n_month]
    Sal <- Sal[dim.correct:n_part,1:n_month]
    Lat_site <- Lat_site[dim.correct:n_part,1:n_month]
    Lon_site <- Lon_site[dim.correct:n_part,1:n_month]
  }
  
  # Because we are dealing with demographic stochasticity we need to repeat the simulations multiple times to determine levels of confidence.
  # determine requested number of stochastic iterations
  iterate_max <- n_day * zmax
  
  # Now within each site work through every successive release date 
  # documenting the spatial and temporal dynamics of the Jellyfish population
  # this function will run for each day, producing a matrix for each day which can then be condensed into an array   
  # this function will also manage the stochastic iterations without the need for for loops.
  Med_den_sim <- future_map(1:iterate_max , drift_sim1, n_day = n_day, n_part = n_part, zmax = zmax, m = m, n_month = n_month, params = params,
                            Temp = Temp, Sal = Sal, Lat_site = Lat_site, Lon_site = Lon_site, ephyra_omit = ephyra_omit, 
                            rel_months = rel_months, demo_stoch = demo_stoch, .options = furrr_options(seed = NULL))
  
  # extract, name, and store, the mean and confidence intervals for the site specific density outputs
  # extract densities and GPS coordinates.
  Med_den <- sapply(Med_den_sim, '[[', 1, simplify = "array")
  lat <- sapply(Med_den_sim, '[[', 2, simplify = "array")
  lon <- sapply(Med_den_sim, '[[', 3, simplify = "array")
  
  # estimate mean
  mean_array <- array(sapply(1:n_day, ci_manual, sim_data = Med_den, output = "mean", iterate_max = iterate_max, zmax = zmax, n_day = n_day), dim = c(n_month,n_month,n_day))
  lat <- array(sapply(1:n_day, ci_manual, sim_data = lat, output = "mean", iterate_max = iterate_max, zmax = zmax, n_day = n_day), dim = c(n_month,n_month,n_day))
  lon <- array(sapply(1:n_day, ci_manual, sim_data = lon, output = "mean", iterate_max = iterate_max, zmax = zmax, n_day = n_day), dim = c(n_month,n_month,n_day))
  # estimate sd
  sd_array <- array(sapply(1:n_day, ci_manual, sim_data = Med_den, output = "sd", iterate_max = iterate_max, zmax = zmax, n_day = n_day), dim = c(n_month,n_month,n_day))
  
  # and remove NaNs.
  mean_array[is.nan(mean_array)] <- NA
  sd_array[is.nan(sd_array)] <- NA
  lat[is.nan(lat)] <- NA
  lon[is.nan(lon)] <- NA
  
  # update progress bar
  pb()
  
  # and return desired outputs
  return(list(mean_array = mean_array, sd_array = sd_array, lat = lat, lon = lon))
}

# 5. Convert density projections into a spatial raster.
combine_rasters <- function(tt, lon, lat, Med_mat, n_day, method, xmn, xmx, ymn, ymx, n_month) {
  # generated black raster space
  r1 <- raster(nrow = ((ymx - ymn)*3), ncol = ((xmx - xmn)*3), # this plots at a resolution of ~33km
               xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx)
  # and fill with empty values
  raster::values(r1) <- 0
  # now added to raster - filling it medusae density spatial points - repeating for each matrix within the array as this way overlapping pixels will be summed rather than masked
  dat <- lapply(1:n_month, rasterise_dens, tt = tt, lon = lon, lat = lat, Med_mat = Med_mat, n_day = n_day, method = method, xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx)
  
  # and combine all existing rasters
  r1 <- do.call(raster::mosaic, c(r1, dat, fun = sum))
  # return desired output
  return(r1)
}

# 6. Internal function called when converting density projections into a spatial raster
rasterise_dens <- function(mt, tt, lon, lat, Med_mat, n_day, method, xmn, xmx, ymn, ymx){
  xcoords <- matrix(lon[,tt,mt], ncol = 1)
  ycoords <- matrix(lat[,tt,mt], ncol = 1)
  if(method == "mean") {density <- matrix(Med_mat[,tt,mt]/n_day, ncol = 1)} # this standardizes the proportional density across the month.
  if(method == "sd") {density <- matrix(Med_mat[,tt,mt], ncol = 1)} # no need to standardize the measure of variation (it is already)
  # condense together ready for converting to a shapefile
  dat <- data.frame(Lon = xcoords, Lat = ycoords, density = density)
  dat <- dat[complete.cases(dat),]
  # convert to spatial points file (only if there is data to use)
  if(dim(dat)[1] > 0) {
    dat <- st_as_sf(dat, coords = c("Lon", "Lat"), crs = 4326)
    # and generate a density raster file 
    template_r <- raster(nrow = ((ymx - ymn)*3), ncol = ((xmx - xmn)*3), # this plots at a resolution of ~33km
                         xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx)
    # and rasterise the density vector
    temp_r <- rasterize(dat, template_r, 'density')
    
  } else {
    # and generate a density raster file 
    template_r <- raster(nrow = ((ymx - ymn)*3), ncol = ((xmx - xmn)*3), # this plots at a resolution of ~33km
                         xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx)
    raster::values(template_r) <- 0
    temp_r <- template_r
  }
  
  # and return desired outputs
  return(temp_r)
}

########################### END OF CODE -------------------------------------------
