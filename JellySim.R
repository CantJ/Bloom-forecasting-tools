# This script outlines the JellySim function that underpins the GoJelly predictive tool for forecasting the spatial dynamics of jellyfish blooms.
# The primary purpose of this function is to combine demographic data and hydrodynamic drifting simulations to forecast temporal and spatial patterns 
# in the density of jellyfish Medusae.

# Primary Author: James Cant
# Contact: james.cant91@gmail.com
# -----------------------------------------------------------------------------

#----------------------------------------------------
# STEP 1: DEFINE PRIMARY PREDICTIVE FUNCTION
#----------------------------------------------------

# This simulation function forms the basis of the predictive tool. 
# Briefly, it combines details outlining the location of initial ephyra release with information on projected abiotic conditions and localized water movements,
# to predict spatial and temporal patterns in Medusae density.
JellySim <- function(pars, driftData, n_days, xmx, xmn, ymx, ymn, m, zmax, R = 50,
                     # pars: Demographic parameters used to parameterise the periodic population models used to simulate jellyfish dynamics 
                     #        (the exact demographic patterns for which information is required will depend on the structure of the demographic functions described in DMat.R)
                     # driftData: the abiotic conditions to which drifting particles are exposed to depending on the timing and location of their release, 
                     #             and the GPS coordinates corresponding with these conditions.
                     # n_days: the number of days comprising a month within provided drifting simulations.
                     # xmx: max longitude covered by the simulation (for use by an internal plotting function for generating model outputs)
                     # xmn: min longitude covered by the simulation
                     # ymx: max latitude covered by the simulation 
                     # ymn: min latitude covered by the simulation
                     #      Currently, these GPS details default to ensure the function focuses on predicting jellyfish blooms within the Baltic Sea.
                     # m: dimensions of demographic projection matrix (allows simulation function to match output dimensions with extents called by demographic functions)
                     # zmax: How many sampling iterations are required to estimate a measure of stochasticity in predicted medusae densities.
                     # R: desired number of columns and rows used for the output raster(s) displaying projected densities (defaults to 50).
                     # -------------------------------------------------
                     # How the model uses these details then depends on two user defined parameters:
                     rel_location, rel_months,
                     # rel_location: a value or vector defining desired locations of Jellyfish ephyra release (i.e. seed population location).
                     # rel_months: a vector of values between 1 and 12 defining the months during which Jellyfish ephyra are released by polyps. 
                     #             Note the simulation returns a visualisation of temporal and spatial patterns in Medusae densities but, during each simulation, Jellyfish are released as Ephyra,
                     #             thus, each simulation requires one time step, following specified release timings, before Jellyfish would be expected to appear. 
                     parallel) {
                     # finally users will need to decide if the function should utilise parallel multicore processing (parallel = T/F).
                     # Note, parallel processing is advised for computations involving multiple release sites, 
                     # but is not possible when using this function as part of the GoJelly Interactive Risk Map (LINK).
  
  # The outputs generated by the JellySim function correspond with a list of raster files outlining the spatial movements and densities of jellyfish populations 
  # expected to arise following their release from a specified location at a specified time of year.
  
  # Load package dependencies
  packages <- c('data.table','terra','sf', 'purrr', 'pbapply', 'gamlss.dist', 'abind')
  installed_packages <- packages %in% rownames(installed.packages())
  if (any(installed_packages == FALSE)) {
    invisible(install.packages(packages[!installed_packages]))
  }
  # Packages loading
  invisible(lapply(packages, library, character.only = TRUE))
  
  # define parallel processing details if requested
  if(parallel == TRUE) {
    # load additional required packages
    packages <- c('parallel', 'foreach', 'future', 'doFuture')
    installed_packages <- packages %in% rownames(installed.packages())
    if (any(installed_packages == FALSE)) {
      install.packages(packages[!installed_packages])
    }
    invisible(lapply(packages, library, character.only = TRUE))
    
    # Open multicore interface
    nCores = detectCores() *0.5 # request 50% of the available cores so as not to overload the system
    plan(multisession, workers = nCores) 
  }
    
  ### 1. Set up simulation 
  
  #Subset the data based on the user defined release locations
  driftuse <- driftData[driftData$Index %in% rel_location,]
  
  # Store the GPS coordinates of each selected location for plotting alongside forecasted densities
  site_coords <- driftuse[, c("Lat", "Lon")]
  class(site_coords) <- "data.frame"
  
  # Determine the temporal extents of the abiotic data for implementing the simulations
  tmax <- dim(driftuse$Tempmat[[1]])[1]
    
  ### 2. Work through each requested release location running density simulations
  site_sim_outputs <- purrr::map(1:length(rel_location), site_sim, pars = pars, EData = driftuse, rel_location = rel_location, rel_months = rel_months,  m = m, zmax = zmax, tmax <- tmax, n_days = n_days, parallel = parallel)
  
  # terminate multicore processing if requested
  if(parallel == TRUE){ plan(sequential) }
  
  # Store output densities and GPS coordinates
  meanDens <- lapply(site_sim_outputs, '[[', 1)
  confDens <- lapply(site_sim_outputs, '[[', 2)
  Lats <- lapply(site_sim_outputs, '[[', 3)
  Lons <- lapply(site_sim_outputs, '[[', 4)
  # Assign output names
  location.name <- sapply(1:length(rel_location), function(x){ 
    site = rel_location[x]
    paste0("Location ", site) } )
  names(meanDens) <- location.name 
  names(confDens) <- location.name 
  names(Lats) <- location.name 
  names(Lons) <- location.name
  
  # Across each location each array consists of matrices defining medusae density simulations if release occurs on a specific day each month (1 to n_days)
  # Displaying the densities and the variability in densities requires corresponding rows across each matrix within each array to be condensed together. 
  # Projections across each requested release location will also be combined together so that all requested projections can be plotted simultaneously.
  
  # condense together days from corresponding months (across all requested sites)
  # This produces arrays comprising monthly matrices documenting temporal and spatial patterns in projected densities following release on any given day.
  meanDens <- lapply(1:length(rel_location), array_reformat, arr = meanDens)
  confDens <- lapply(1:length(rel_location), array_reformat, arr = confDens)
  Lats <- lapply(1:length(rel_location), array_reformat, arr = Lats)
  Lons <- lapply(1:length(rel_location), array_reformat, arr = Lons)
  
  # Combine together information from across release locations
  meanDens <- do.call(abind, c(lapply(meanDens, '['), along = 1))
  confDens <- do.call(abind, c(lapply(confDens, '['), along = 1))
  Lats <- do.call(abind, c(lapply(Lats, '['), along = 1))
  Lons <- do.call(abind, c(lapply(Lons, '['), along = 1))
  # Ensure that each matrix only contains entries for times for which there is corresponding GPS and abiotic information.
  meanDens[is.na(Lats)] <- NA
  confDens[is.na(Lats)] <- NA
  Lats[is.na(meanDens)] <- NA
  Lons[is.na(meanDens)] <- NA
  
  # Strip out each column (across the whole array) to produce temporal rasters displaying how medusae density changes over time (and how within a month the simulations can vary.
      # loop through each matrix quadruplet (Den_mean, dens_conf, Lat, Long)
      # each time extracting successive columns and generating a density raster before storing it (although lapply does this all simultaneously)
  meanRast <- rast(lapply(1:dim(meanDens)[2], DensityRaster, lon = Lons, lat = Lats, Dens = meanDens, R = R, xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx))
  confRast <- rast(lapply(1:dim(confDens)[2], DensityRaster, lon = Lons, lat = Lats, Dens = confDens, R = R, xmn = xmn, xmx = xmx, ymn = ymn, ymx = ymx))
      
  # Name raster layers
  layer.name <- sapply(1:nlyr(meanRast), function(x){ paste0("Month ", x) } )
  names(meanRast) <- layer.name
  names(confRast) <- layer.name
    
  # and return desired outputs
  return(list(mean = meanRast, conf = confRast, site = site_coords))
}



#----------------------------------------------------
# STEP 2: INTERNAL FUNCTIONS
#----------------------------------------------------

# 1. Function to apply density simulations across selected size, with potential for implementing parallel processing. -----------------------------------------------------------
site_sim <- function(loc, pars, EData, rel_location, rel_months, m, zmax, tmax, n_days, parallel){
  
  # isolate a selected site
  site <- rel_location[loc]
  
  # Progress marker
  cat('Location', site,'\n')
  
  # Extract and unlist possible temperature and location details encountered for particles released from the selected site
  Temp <- EData[EData$Index == site,]$Tempmat[[1]]
  Sal <- EData[EData$Index == site,]$Salmat[[1]]
  Lat_site <- EData[EData$Index == site,]$Latmat[[1]]
  Lon_site <- EData[EData$Index == site,]$Lonmat[[1]]
  
  # For each requested site, the simulation will work by isolating the full sequence of conditions individuals released on a given day are expected to experience during their subsequent drifting pathway.
  # This will be used to determine the full transition of these individuals, before then repeating the process for each subsequent release day. 
  
  # Using parallel processing if requested
  if(parallel == TRUE) {
    output <- foreach(n = 1:n_days, .inorder = TRUE, .options.future = list(seed = TRUE)) %dofuture% {
      
      # set up indexing for selected monthly sequence 
      day_select <- seq(n, tmax, by = n_days)
      
      # Determine the number of months covered by the selected simulation iteration
      Temp_use <- Temp[day_select,]
      ReAlign <- nrow(Temp_use) != ncol(Temp_use) # do months require omitting? (to ensure dimensions can be realigned if necessary)
      n_month <- dim(Temp_use[,colSums(Temp_use, na.rm = T)!=0])[2] # if there is no data for later months they need omitting from processing
    
      # Vector of months during which Ephyra production cannot occur
      ephyra_omit <- seq(1:n_month)[!(seq(1:n_month) %in% rel_months)]  
    
      # isolate corresponding abiotic details for selected day
      Temp_use <- Temp[day_select, 1:n_month]
      Sal_use <- Sal[day_select, 1:n_month]
      Lon <- Lon_site[day_select, 1:n_month]
      Lat <- Lat_site[day_select, 1:n_month]
      # Reformat GPS matrix
      Lat <- t(apply(Lat,1,function(x){x[order(!is.na(x))]}))
      Lon <- t(apply(Lon,1,function(x){x[order(!is.na(x))]}))
      if(ReAlign == TRUE){
        Lat <- rbind(Lat, rep(NA, n_month))
        Lat <- cbind(Lat, rep(NA, nrow(Lat)))
        Lon <- rbind(Lon, rep(NA, n_month))
        Lon <- cbind(Lon, rep(NA, nrow(Lon)))
      }
    
      # Simultaneously, each daily density simulation needs to be repeated to allow for demographic stochasticity across vital rate parameters
      DensSim <- lapply(1:zmax, function(z){
        
        # define fixed simulation parameters and temporary output storage
        initial_pop <- numeric(m+4) # population structure vector
        Polyp_dens_store <- numeric(n_month+1) # simulated estimates of polyp density
        # storage for population projections
        nt_med <- matrix(0, nrow = m, ncol = n_month)
        Nt_med <- matrix(NA, nrow = n_month, ncol = n_month)
        Nt_ephyra <- matrix(NA, nrow = n_month, ncol = n_month)
      
        # generate initial polyp density and define demographic transition probability matrices
        pop_sim <- DMat(m = m, n_month = n_month, pars = pars, Temp = Temp_use[1,], Sal = Sal_use[1,],
                               rel_months = rel_months, ephyra_omit = ephyra_omit)
      
        # store population indexing parameter
        index <- pop_sim$Adjust
        # store initial polyp density
        Polyp_dens_store[index] <- pop_sim$DensityStart
        # store initial seed population density
        initial_pop[2] <- Polyp_dens_store[index]
      
        # run first monthly iteration
        pop_vec <- pop_sim$matB[,,index]%*%initial_pop
        # store required outputs
        nt_med[, index] <- pop_vec[5:204,] 
        Nt_med[1, index] <- pop_sim$h[index] * sum(nt_med[, index])
        Nt_ephyra[1, index] <- pop_vec[4,]
        # important to retain polyp density for next monthly run through
        Polyp_dens_store[index+1] <- pop_vec[2,]
      
        # Iteratively estimate and store subsequent medusae densities
        for(t in (index+1):n_month){
          pop_vec <- pop_sim$matB[,,t]%*%pop_vec
          nt_med[, t] <- pop_vec[5:204,]
          Nt_med[1, t] <- pop_sim$h[t] * sum(nt_med[, t])
          Nt_ephyra[1, t] <- pop_vec[4,]
        }
      
        # So far this has simulated the trajectory of a single release. 
        # The function now needs to simulate the continued release of ephyra from this initial release point, each time using the polyp density determined on the previous run.
        # To achieve this the function will loop through the remaining isolated abiotic sequences each time using the previously derived seed population density.
      
        for(ii in 2:n_month) {
          # redefine define transition functions
          pop_sim <- DMat(m = m, n_month = n_month, pars = pars, Temp = Temp_use[ii,], Sal = Sal_use[ii,], rel_months = rel_months, ephyra_omit = ephyra_omit)
          # extract initial population indexing parameter
          index <- pop_sim$Adjust
          # insert starting seed population polyp density into initial population vector
          initial_pop[2] <- Polyp_dens_store[index]
        
          # run first iteration
          pop_vec <- pop_sim$matB[,,index]%*%initial_pop
          # and store required outputs
          nt_med[, index] <- pop_vec[5:204,] 
          Nt_med[ii, index] <- pop_sim$h[index] * sum(nt_med[, index])
          Nt_ephyra[ii, index] <- pop_vec[4,]
          # retain polyp density for next monthly iteration
          Polyp_dens_store[index+1] <- pop_vec[2,]
        
          # Iteratively estimate and store subsequent medusae densities
          if(index != n_month){
            for(t in (index+1):n_month){
              pop_vec <- pop_sim$matB[,,t]%*%pop_vec
              nt_med[, t] <- pop_vec[5:204,]
              Nt_med[ii, t] <- pop_sim$h[t] * sum(nt_med[, t])
              Nt_ephyra[ii, t] <- pop_vec[4,]
            }
          }
        }
      
        # convert medusae density estimates into a relative measure (i.e. the proportion of individuals as a function of the number originally produced)
        e.initial <- apply(Nt_ephyra, 1, max, na.rm = T) # calculate the number of ephyra initially released across each release cycle
        Nt_med <- Nt_med/e.initial # divide medusae densities by the corresponding initial release value.
        Nt_med[is.nan(Nt_med)]<-0 # remove NANs
      
        # Add missing columns in needed to ensure monthly densities align across iterations
        if(ReAlign == TRUE) {
          Nt_med <- rbind(Nt_med, rep(NA, n_month))
          Nt_med <- cbind(Nt_med, rep(NA, nrow(Nt_med)))
        }
      
        # return simulated densities
        return(Nt_med)})
    
      # Calculate mean and variance (confidence) across stochastic density estimates
      meanMat <- DensCalcs(DensSim, 'mean')
      confMat <- DensCalcs(DensSim, 'sd')
      
      # Return desired outputs from parallel processing
      outList <- list(meanMat, confMat, Lat, Lon)
      outList
    }
  
    # Combine daily iterations into arrays for each selected release location
    meanDen <- array(unlist(sapply(output,"[",1)), dim = c(dim(output[[1]][[1]]), n_days))
    confDen <- array(unlist(sapply(output,"[",2)), dim = c(dim(output[[1]][[2]]), n_days))
    Lat <- array(unlist(sapply(output,"[",3)), dim = c(dim(output[[1]][[3]]), n_days))
    Lon <- array(unlist(sapply(output,"[",4)), dim = c(dim(output[[1]][[4]]), n_days))
    
  } else {
    # Define storage
    meanList <- confList <- latList <- lonList <- list()
    
    # the simulation will always start in January so needs to repeat for each day of the month.
    for(n in 1:n_days){
      # set up indexing for selected monthly sequence 
      day_select <- seq(n, tmax, by = n_days)
      
      # Determine the number of months covered by the selected simulation iteration
      Temp_use <- Temp[day_select,]
      ReAlign <- nrow(Temp_use) != ncol(Temp_use) # do months require omitting? (to ensure dimensions can be realigned if necessary)
      n_month <- dim(Temp_use[,colSums(Temp_use, na.rm = T)!=0])[2] # if there is no data for later months they need omitting from processing
      
      # Vector of months during which Ephyra production cannot occur
      ephyra_omit <- seq(1:n_month)[!(seq(1:n_month) %in% rel_months)]  
      
      # isolate corresponding abiotic details for selected day
      Temp_use <- Temp[day_select, 1:n_month]
      Sal_use <- Sal[day_select, 1:n_month]
      Lon <- Lon_site[day_select, 1:n_month]
      Lat <- Lat_site[day_select, 1:n_month]
      # Reformat GPS matrix
      Lat <- t(apply(Lat,1,function(x){x[order(!is.na(x))]}))
      Lon <- t(apply(Lon,1,function(x){x[order(!is.na(x))]}))
      if(ReAlign == TRUE){
        Lat <- rbind(Lat, rep(NA, n_month))
        Lat <- cbind(Lat, rep(NA, nrow(Lat)))
        Lon <- rbind(Lon, rep(NA, n_month))
        Lon <- cbind(Lon, rep(NA, nrow(Lon)))
      }
      latList[[n]] <- Lat # Store GPS details
      lonList[[n]] <- Lon
      
      # Simultaneously, each daily density simulation needs to be repeated to allow for demographic stochasticity across vital rate parameters
      DensSim <- pblapply(1:zmax, function(z){
        
        # define fixed simulation parameters and temporary output storage
        initial_pop <- numeric(m+4) # population structure vector
        Polyp_dens_store <- numeric(n_month+1) # simulated estimates of polyp density
        # storage for population projections
        nt_med <- matrix(0, nrow = m, ncol = n_month)
        Nt_med <- matrix(NA, nrow = n_month, ncol = n_month)
        Nt_ephyra <- matrix(NA, nrow = n_month, ncol = n_month)
        
        # generate initial polyp density and define demographic transition probability matrices
        pop_sim <- DMat(m = m, n_month = n_month, pars = pars, Temp = Temp_use[1,], Sal = Sal_use[1,],
                               rel_months = rel_months, ephyra_omit = ephyra_omit)
        
        # store population indexing parameter
        index <- pop_sim$Adjust
        # store initial polyp density
        Polyp_dens_store[index] <- pop_sim$DensityStart
        # store initial seed population density
        initial_pop[2] <- Polyp_dens_store[index]
        
        # run first monthly iteration
        pop_vec <- pop_sim$matB[,,index]%*%initial_pop
        # store required outputs
        nt_med[, index] <- pop_vec[5:204,] 
        Nt_med[1, index] <- pop_sim$h[index] * sum(nt_med[, index])
        Nt_ephyra[1, index] <- pop_vec[4,]
        # important to retain polyp density for next monthly run through
        Polyp_dens_store[index+1] <- pop_vec[2,]
        
        # Iteratively estimate and store subsequent medusae densities
        for(t in (index+1):n_month){
          pop_vec <- pop_sim$matB[,,t]%*%pop_vec
          nt_med[, t] <- pop_vec[5:204,]
          Nt_med[1, t] <- pop_sim$h[t] * sum(nt_med[, t])
          Nt_ephyra[1, t] <- pop_vec[4,]
        }
        
        # So far this has simulated the trajectory of a single release. 
        # The function now needs to simulate the continued release of ephyra from this initial release point, each time using the polyp density determined on the previous run.
        # To achieve this the function will loop through the remaining isolated abiotic sequences each time using the previously derived seed population density.
        
        for(ii in 2:n_month) {
          # redefine define transition functions
          pop_sim <- DMat(m = m, n_month = n_month, pars = pars, Temp = Temp_use[ii,], Sal = Sal_use[ii,], rel_months = rel_months, ephyra_omit = ephyra_omit)
          # extract initial population indexing parameter
          index <- pop_sim$Adjust
          # insert starting seed population polyp density into initial population vector
          initial_pop[2] <- Polyp_dens_store[index]
          
          # run first iteration
          pop_vec <- pop_sim$matB[,,index]%*%initial_pop
          # and store required outputs
          nt_med[, index] <- pop_vec[5:204,] 
          Nt_med[ii, index] <- pop_sim$h[index] * sum(nt_med[, index])
          Nt_ephyra[ii, index] <- pop_vec[4,]
          # retain polyp density for next monthly iteration
          Polyp_dens_store[index+1] <- pop_vec[2,]
          
          # Iteratively estimate and store subsequent medusae densities
          if(index != n_month){
            for(t in (index+1):n_month){
              pop_vec <- pop_sim$matB[,,t]%*%pop_vec
              nt_med[, t] <- pop_vec[5:204,]
              Nt_med[ii, t] <- pop_sim$h[t] * sum(nt_med[, t])
              Nt_ephyra[ii, t] <- pop_vec[4,]
            }
          }
        }
        
        # convert medusae density estimates into a relative measure (i.e. the proportion of individuals as a function of the number originally produced)
        e.initial <- apply(Nt_ephyra, 1, max, na.rm = T) # calculate the number of ephyra initially released across each release cycle
        Nt_med <- Nt_med/e.initial # divide medusae densities by the corresponding initial release value.
        Nt_med[is.nan(Nt_med)]<-0 # remove NANs
        
        # Add missing columns in needed to ensure monthly densities align across iterations
        if(ReAlign == TRUE) {
          Nt_med <- rbind(Nt_med, rep(NA, n_month))
          Nt_med <- cbind(Nt_med, rep(NA, nrow(Nt_med)))
        }
        
        # return simulated densities
        return(Nt_med)})
      
      # Calculate mean and variance (confidence) across stochastic density estimates
      meanList[[n]] <- DensCalcs(DensSim, 'mean')
      confList[[n]] <- DensCalcs(DensSim, 'sd')
    }
    
    # Combine daily iterations into arrays for each selected release location
    meanDen <- array(unlist(meanList), dim = c(dim(meanList[[1]]),n_days))
    confDen <- array(unlist(confList), dim = c(dim(confList[[1]]),n_days))
    Lat <- array(unlist(latList), dim = c(dim(latList[[1]]),n_days))
    Lon <- array(unlist(lonList), dim = c(dim(lonList[[1]]),n_days))
  }
  
  # Clean arrays
  meanDen[is.nan(meanDen)] <- NA
  confDen[is.nan(confDen)] <- NA
  Lat[is.nan(Lon)] <- NA
  Lon[is.nan(Lat)] <- NA
  
  # Return outputs
  return(list(mean = meanDen, conf = confDen, Lat = Lat, Lon = Lon))
}



# 2. Estimate element-wise mean or standard deviation for a list of matrices -----------------------------------------------------------
DensCalcs <- function(lst, calc){
  n <- length(lst) # number of matrices
  rc <- dim(lst[[1]]) # matrix dimensions
  ar1 <- array(unlist(lst), c(rc, n)) # unlist matrices into an array
  apply(ar1, c(1, 2), calc)
}



# 3. Define function for reformatting arrays to combine observations across corresponding days. ----------------------------------------------------------- 
array_reformat <- function(loc, arr){
  tmp <- asplit(arr[[loc]][,,], MARGIN = 1) # split apart and condense together corresponding matrix rows from across the array
  new <- sapply(1:length(tmp), function(x){ t(tmp[[x]])}, simplify = 'array') # transpose aggregated rows
  return(new)
}



# 4. Combine corresponding temporal density projections into a spatial raster. -----------------------------------------------------------
DensityRaster <- function(ii, lon, lat, Dens, R, xmn, xmx, ymn, ymx) {
  
  # generate blank raster space
  TmpR <- rast(nrow = R, ncol = R, xmin = xmn, xmax = xmx, ymin = ymn, ymax = ymx, vals = 0)
  
  # Extract GPS coordinates
  xcoords <- matrix(lon[,ii,], ncol = 1)
  ycoords <- matrix(lat[,ii,], ncol = 1)
  # Extract corresponding density estimates
  density <- matrix(Dens[,ii,], ncol = 1)
  
  # Convert to a shapefile and rasterise
  dat <- data.frame(Lon = xcoords, Lat = ycoords, density = density)
  dat <- dat[complete.cases(dat),]
  if(dim(dat)[1] > 0) { # only works if there is projected values to work with
    dat <- st_as_sf(dat, coords = c("Lon", "Lat"), crs = 4326)
    # Rasterise 
    DensRast <- rasterize(dat, TmpR, 'density')
  } else { # otherwise the function returns a blank raster.
    DensRast <- TmpR
  }
  
  # Populate density raster NAs with zeros
  DensRast <- mosaic(DensRast, TmpR, fun = 'max')
  
  # and return desired outputs
  return(DensRast)
}

########################### END OF CODE -------------------------------------------
